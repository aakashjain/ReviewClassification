{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training and testing datasets\n",
    "data_train = load_files('aclImdb/train/', categories=['neg', 'pos'])\n",
    "data_test = load_files('aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts documents to word count vectors, then transforms to smoothed TFIDF scores\n",
    "tfidf_vect = TfidfVectorizer(decode_error='replace',  # replace chars with decoding problems\n",
    "                             strip_accents='unicode', # replace accented chars\n",
    "                             stop_words='english',    # remove stopwords with built-in list\n",
    "                             lowercase=True,          # convert all words to lowercase\n",
    "                             analyzer='word',         # use words as the basic unit\n",
    "                             smooth_idf=True)         # add 1 to DF\n",
    "\n",
    "# multinomial naive bayes classifier\n",
    "bayes = MultinomialNB()\n",
    "\n",
    "# pipeline for our learning strategy\n",
    "pipeline = Pipeline([('tfidf_vect', tfidf_vect),\n",
    "                     ('bayes', bayes)])\n",
    "\n",
    "# different options we want to explore\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3), (1,4)], # range of feature ngram size\n",
    "    'tfidf_vect__use_idf': [True, False],             # use TFIDF or only TF\n",
    "    'tfidf_vect__sublinear_tf': [True, False],        # use 1+log(TF)\n",
    "    'tfidf_vect__min_df': [0, 1, 2],                  # minimum df to consider\n",
    "    'bayes__alpha': [0.01, 0.1, 0.5, 1, 2, 10, 100],  # smoothing param for NB\n",
    "}\n",
    "\n",
    "# performs parallel search on all combinations of parameters\n",
    "# evaluates all options and selects the one with the best score\n",
    "clf = GridSearchCV(pipeline, params, n_jobs=2)        # use all cpu cores\n",
    "\n",
    "# perform the search by fitting on training data\n",
    "clf = clf.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen params: {'tfidf_vect__sublinear_tf': True, 'tfidf_vect__use_idf': True, 'tfidf_vect__min_df': 0, 'tfidf_vect__ngram_range': (1, 3), 'bayes__alpha': 0.1}\n",
      "Model score: 0.88224\n"
     ]
    }
   ],
   "source": [
    "# resultant classifier model\n",
    "print 'Chosen params: ' + str(clf.best_params_)\n",
    "print 'Model score: ' + str(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85.556%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.89      0.86     12500\n",
      "        pos       0.88      0.82      0.85     12500\n",
      "\n",
      "avg / total       0.86      0.86      0.86     25000\n",
      "\n",
      "[[11132  1368]\n",
      " [ 2243 10257]]\n"
     ]
    }
   ],
   "source": [
    "# use it to predict on the testing set\n",
    "predicted = clf.predict(data_test.data)\n",
    "\n",
    "# show metrics\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print 'Test accuracy: ' + str(100*acc) + '%'\n",
    "print classification_report(data_test.target, predicted, target_names=data_test.target_names)\n",
    "print confusion_matrix(data_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "x = [\"I understand a lot of people have problems with the movie's ending. I can understand the frustration.\"\n",
    "     \" The climactic twist takes away from the central premise, it reminded me of 'The Reaping' in some way.\"\n",
    "     \" And besides being incongruous to theherok main storyline, it further had the problem of being very poorly executed.\",\n",
    "     \"This movie is pretty great. The acting is somewhat bad but the direction and writing makes up for it.\"]\n",
    "y = clf.predict(foo)\n",
    "print [data_test.target_names[i] for i in y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
